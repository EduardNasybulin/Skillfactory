Отчёт о проделаной работе:

За основу было взято Baseline решение и к нему было сделано ряд добавлений в основном следуя рекомендациям.

-Очистка данных и их анализ, EDA
-Извлечение числовых признаков, парсинг признаков, понижение размерности
-Логарифмизация и нормализация признаков (несколько методов)
-Генерация новых признаков.
-Encoding признаков
-За счёт вышеописаных удалось значительно поднять метрику по сравнению с Baseline

-Логарифмизация target (сильно помогла ML)
-Были поробованы модели Extra Tree Regressor и XGB Regressor в дополнение к CatBoost

NN:
-Добавление слоёв в нейросеть, перебор параметров активации, LR

NPL:
-Очистка текста: удаление лишних символов
-Обработка: лемматизация
-Stopword

Images:
-Подбор параметров аугуметации (albumentation)
-Управление LR через ReduceLROnPlateau
-Fine tuning

Assembling:
-Ансамблирование градиентного бустинга и нейронной сети (усреднение их предсказаний)